{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''IMPORTING PACKAGES'''\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "\n",
    "import sys\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628563409</td>\n",
       "      <td>1299012705270071296</td>\n",
       "      <td>2020-08-27 15:55:38</td>\n",
       "      <td>JDMFV</td>\n",
       "      <td>edwinvgerven üíñ Tag/Follow #EATSLEEPSUBARU  for...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>247</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8845011674...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628563409</td>\n",
       "      <td>1298413811679076352</td>\n",
       "      <td>2020-08-26 00:15:50</td>\n",
       "      <td>JDMFV</td>\n",
       "      <td>wrx_jan üíñ Tag/Follow #EATSLEEPSUBARU  for a fe...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>249</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8845011674...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>628563409</td>\n",
       "      <td>1297213379271065600</td>\n",
       "      <td>2020-08-22 16:45:45</td>\n",
       "      <td>JDMFV</td>\n",
       "      <td>ellie.wrx üíñ Tag/Follow #EATSLEEPSUBARU  for a ...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8845011674...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628563409</td>\n",
       "      <td>1298826481129402368</td>\n",
       "      <td>2020-08-27 03:35:38</td>\n",
       "      <td>JDMFV</td>\n",
       "      <td>subi17sti üíñ Tag/Follow #EATSLEEPSUBARU  for a ...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8845011674...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>628563409</td>\n",
       "      <td>1298287576902561792</td>\n",
       "      <td>2020-08-25 15:54:14</td>\n",
       "      <td>JDMFV</td>\n",
       "      <td>cloudburzt üíñ Tag/Follow #EATSLEEPSUBARU  for a...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>245</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8845011674...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id            status_id          created_at screen_name  \\\n",
       "0  628563409  1299012705270071296 2020-08-27 15:55:38       JDMFV   \n",
       "1  628563409  1298413811679076352 2020-08-26 00:15:50       JDMFV   \n",
       "2  628563409  1297213379271065600 2020-08-22 16:45:45       JDMFV   \n",
       "3  628563409  1298826481129402368 2020-08-27 03:35:38       JDMFV   \n",
       "4  628563409  1298287576902561792 2020-08-25 15:54:14       JDMFV   \n",
       "\n",
       "                                                text     source  \\\n",
       "0  edwinvgerven üíñ Tag/Follow #EATSLEEPSUBARU  for...  Instagram   \n",
       "1  wrx_jan üíñ Tag/Follow #EATSLEEPSUBARU  for a fe...  Instagram   \n",
       "2  ellie.wrx üíñ Tag/Follow #EATSLEEPSUBARU  for a ...  Instagram   \n",
       "3  subi17sti üíñ Tag/Follow #EATSLEEPSUBARU  for a ...  Instagram   \n",
       "4  cloudburzt üíñ Tag/Follow #EATSLEEPSUBARU  for a...  Instagram   \n",
       "\n",
       "   display_text_width  is_quote  is_retweet  favorite_count  ...  \\\n",
       "0                 247     False       False               0  ...   \n",
       "1                 249     False       False               0  ...   \n",
       "2                 251     False       False               0  ...   \n",
       "3                 251     False       False               0  ...   \n",
       "4                 245     False       False               0  ...   \n",
       "\n",
       "                                   profile_image_url reply_to_user_id  \\\n",
       "0  http://pbs.twimg.com/profile_images/8845011674...              NaN   \n",
       "1  http://pbs.twimg.com/profile_images/8845011674...              NaN   \n",
       "2  http://pbs.twimg.com/profile_images/8845011674...              NaN   \n",
       "3  http://pbs.twimg.com/profile_images/8845011674...              NaN   \n",
       "4  http://pbs.twimg.com/profile_images/8845011674...              NaN   \n",
       "\n",
       "  reply_to_screen_name place_url place_name place_full_name place_type  \\\n",
       "0                  NaN       NaN        NaN             NaN        NaN   \n",
       "1                  NaN       NaN        NaN             NaN        NaN   \n",
       "2                  NaN       NaN        NaN             NaN        NaN   \n",
       "3                  NaN       NaN        NaN             NaN        NaN   \n",
       "4                  NaN       NaN        NaN             NaN        NaN   \n",
       "\n",
       "  country country_code reply_to_status_id  \n",
       "0     NaN          NaN                NaN  \n",
       "1     NaN          NaN                NaN  \n",
       "2     NaN          NaN                NaN  \n",
       "3     NaN          NaN                NaN  \n",
       "4     NaN          NaN                NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Read in BRZ JSON data'''\n",
    "subBRZ = pd.read_json(\"/Users/avanelson/Desktop/IST652 Python/subBRZ.JSON\") #read in tweets on Subaru BRZ\n",
    "\n",
    "print(len(subBRZ))\n",
    "subBRZ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    0     edwinvgerven üíñ Tag/Follow #EATSLEEPSUBAR...\n",
      "dtype: object\n",
      "n 16\n",
      "tag 13\n",
      "follow 13\n",
      "eatsleepsubaru 13\n",
      "brz 10\n",
      "subaru 5\n",
      "memories 4\n",
      "sti 3\n",
      "frs 3\n",
      "touge 3\n",
      "battle 3\n",
      "ph 3\n",
      "n2015 3\n",
      "nfor 3\n",
      "rules 3\n",
      "fe 2\n",
      "new 2\n",
      "like 2\n",
      "car 2\n",
      "wrx 2\n",
      "toyota 2\n",
      "next 2\n",
      "last 2\n",
      "carbon 2\n",
      "miles 2\n",
      "since 2\n",
      "life 2\n",
      "ye 2\n",
      "cafe 2\n",
      "day 2\n",
      "name 2\n",
      "edwinvgerven 1\n",
      "wrx_jan 1\n",
      "ellie.wrx 1\n",
      "subi 1\n",
      "17sti 1\n",
      "cloudburzt 1\n",
      "subiebry 1\n",
      "f 1\n",
      "frankie 1\n",
      "ljayfarris 1\n",
      "ghozti_chick 1\n",
      "@iggy_wrx 1\n",
      "wrxhigh 1\n",
      "thirsti 1\n",
      "@mvrk_007 1\n",
      "outdoors 1\n",
      "calling 1\n",
      "forster 1\n",
      "overland 1\n",
      "getting 1\n",
      "ready 1\n",
      "testing 1\n",
      "weekend 1\n",
      "ao 1\n",
      "wake 1\n",
      "reality 1\n",
      "nothing 1\n",
      "ever 1\n",
      "goes 1\n",
      "plann 1\n",
      "choose 1\n",
      "choo 1\n",
      "i'll 1\n",
      "show 1\n",
      "feels 1\n",
      "nnow 1\n",
      "i'm 1\n",
      "found 1\n",
      "something 1\n",
      "good 1\n",
      "try 1\n",
      "sports 1\n",
      "always 1\n",
      "dreamed 1\n",
      "b 1\n",
      "camber 1\n",
      "jdm 1\n",
      "wheels 1\n",
      "wide 1\n",
      "gt8 1\n",
      "first 1\n",
      "time 1\n",
      "two 1\n",
      "ot 1\n",
      "another 1\n",
      "angle 1\n",
      "r53 1\n",
      "need 1\n",
      "genuine 1\n",
      "front 1\n",
      "lip 1\n",
      "japan 1\n",
      "fitted 1\n",
      "specialized 1\n",
      "roubaix 1\n",
      "took 1\n",
      "test 1\n",
      "run 1\n",
      "laguna 1\n",
      "seca 1\n",
      "years 1\n",
      "30k 1\n",
      "countless 1\n",
      "dream 1\n",
      "real 1\n",
      "love 1\n",
      "creative 1\n",
      "stuff 1\n",
      "nfrom 1\n",
      "nebi 1\n",
      "suns 1\n",
      "tongues 1\n",
      "@stoooart 1\n",
      "nlook 1\n",
      "ae86 1\n",
      "missing 1\n",
      "mods 1\n",
      "forgot 1\n",
      "post 1\n",
      "simple 1\n",
      "yet 1\n",
      "thank 1\n",
      "everyone 1\n",
      "listened 1\n",
      "appa 1\n",
      "smoking 1\n",
      "hot 1\n",
      "today 1\n",
      "many 1\n",
      "thanks 1\n",
      "zerobreau 1\n",
      "@crazywookiee 1\n",
      "already 1\n",
      "planning 1\n",
      "track 1\n",
      "never 1\n",
      "seem 1\n",
      "able 1\n",
      "sleep 1\n",
      "early 1\n",
      "nig 1\n",
      "brazilian 1\n",
      "world 1\n",
      "cup 1\n",
      "national 1\n",
      "team 1\n",
      "mus 1\n",
      "@subiewoo 1\n",
      "better 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/avanelson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''Convert BRZ text to list'''\n",
    "BRZwords = subBRZ[['text']].apply(str)\n",
    "print(BRZwords)\n",
    "\n",
    "BRZ_list = BRZwords.to_numpy().tolist()\n",
    "type(BRZ_list)\n",
    "\n",
    "#from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "#tokens = tt.tokenize(text_list)\n",
    "\n",
    "len(BRZ_list)\n",
    "BRZ_tokens = [tok.lower() for msg in BRZ_list for tok in tt.tokenize(msg)]\n",
    "\n",
    "len(BRZ_tokens)\n",
    "\n",
    "\n",
    "'''Frequency Distribution'''\n",
    "#download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#filter stopwords from tokens\n",
    "BRZ_filter_tokens = [] \n",
    "  \n",
    "for w in BRZ_tokens: \n",
    "    if w not in nltk_stopwords: \n",
    "        BRZ_filter_tokens.append(w) \n",
    "        \n",
    "\n",
    "#view FD to make sure filter worked...\n",
    "BRZ_FD = nltk.FreqDist(BRZ_filter_tokens)\n",
    "BRZ_FD.most_common(30)\n",
    "\n",
    "#Process token list for FD\n",
    "import re\n",
    "def alpha_filter(w): \n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "BRZtoken_list = [tok for tok in BRZ_filter_tokens if not alpha_filter(tok)]\n",
    "BRZtoken_list[:30]\n",
    "\n",
    "#remove hashtag symbol from tokens\n",
    "BRZtoken_list = [s.replace('#', '') for s in BRZtoken_list]\n",
    "\n",
    "#display word frequency\n",
    "fBRZ_FD = nltk.FreqDist(BRZtoken_list)\n",
    "top_words = fBRZ_FD.most_common(150)\n",
    "fBRZ = {}\n",
    "for word, freq in top_words:\n",
    "    if word not in fBRZ.keys():\n",
    "        fBRZ[word] = freq\n",
    "    print(word, freq)\n",
    "    \n",
    "fBRZ_df = pd.DataFrame.from_dict(fBRZ, orient='index' )\n",
    "fBRZ_df.to_csv('/Users/avanelson/Desktop/IST652 Python/Python Project/frequency_BRZ.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mopinion_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('opinion_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/opinion_lexicon\u001b[0m\n\n  Searched in:\n    - '/Users/avanelson/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/share/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mopinion_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('opinion_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/opinion_lexicon.zip/opinion_lexicon/\u001b[0m\n\n  Searched in:\n    - '/Users/avanelson/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/share/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-38bf0d262ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#create positive and negative lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpos_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopinion_lexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mneg_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopinion_lexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mopinion_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('opinion_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/opinion_lexicon\u001b[0m\n\n  Searched in:\n    - '/Users/avanelson/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/share/nltk_data'\n    - '/Users/avanelson/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "'''BRZ SENTIMENT ANALYSIS'''\n",
    "\n",
    "#create positive and negative lists\n",
    "pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())\n",
    "\n",
    "#define function to generate sentiment from tweets\n",
    "def sentiment(tweet):\n",
    "  senti=0\n",
    "  words = [tok.lower() for tok in tt.tokenize(tweet)]\n",
    "  for word in words:\n",
    "    if word in pos_list:\n",
    "      senti += 1\n",
    "    elif word in neg_list:\n",
    "      senti -= 1\n",
    "  return senti\n",
    "\n",
    "#apply sentiment function to original dataframe\n",
    "BRZsent = subBRZ['text'].apply(sentiment)\n",
    "\n",
    "#display results\n",
    "print(\"Sentiment Scores for the Subaru BRZ:\")\n",
    "print(BRZsent[:15])\n",
    "avg_BRZ_sentiment = sum(BRZsent)/len(BRZsent)\n",
    "print(\"The average sentiment toward the BRZ on twitter is\", avg_BRZ_sentiment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEGIN TOYOTA 86'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''BEGIN TOYOTA 86'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>url</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>profile_expanded_url</th>\n",
       "      <th>profile_background_url</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1189857712990871552</td>\n",
       "      <td>1298906891498782720</td>\n",
       "      <td>2020-08-27 08:55:10</td>\n",
       "      <td>en_toyota</td>\n",
       "      <td>TOYOTA GAZOO Racing photos\\n\\n#TGRgram\\n\\nGT86...</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293960737686200320</td>\n",
       "      <td>1298686824555126784</td>\n",
       "      <td>2020-08-26 18:20:42</td>\n",
       "      <td>gr86forum</td>\n",
       "      <td>New Toyota GR86 Rendered in Different Colors!\\...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>https://t.co/JiiC6XyrxF</td>\n",
       "      <td>https://t.co/JiiC6XyrxF</td>\n",
       "      <td>https://www.GR86.org/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1169428135177113600</td>\n",
       "      <td>1298497641106403328</td>\n",
       "      <td>2020-08-26 05:48:57</td>\n",
       "      <td>horus_works</td>\n",
       "      <td>#Toyota86 or #SubaruBRZ ü§∑‚Äç‚ôÇÔ∏è\\nWhich one would ...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>991857623099170816</td>\n",
       "      <td>1298477912971075584</td>\n",
       "      <td>2020-08-26 04:30:33</td>\n",
       "      <td>raceworks172</td>\n",
       "      <td>‚ù§Ô∏è Hand built coilovers on sale with code NOVA...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>280</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://t.co/N5cLK4Z95U</td>\n",
       "      <td>https://t.co/N5cLK4Z95U</td>\n",
       "      <td>https://raceworkscoilovers.com</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>991857623099170816</td>\n",
       "      <td>1296618043745820672</td>\n",
       "      <td>2020-08-21 01:20:06</td>\n",
       "      <td>raceworks172</td>\n",
       "      <td>Daily stance. Because DGAF.\\n\\nhttps://t.co/Qh...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>238</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>https://t.co/N5cLK4Z95U</td>\n",
       "      <td>https://t.co/N5cLK4Z95U</td>\n",
       "      <td>https://raceworkscoilovers.com</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id            status_id          created_at   screen_name  \\\n",
       "0  1189857712990871552  1298906891498782720 2020-08-27 08:55:10     en_toyota   \n",
       "1  1293960737686200320  1298686824555126784 2020-08-26 18:20:42     gr86forum   \n",
       "2  1169428135177113600  1298497641106403328 2020-08-26 05:48:57   horus_works   \n",
       "3   991857623099170816  1298477912971075584 2020-08-26 04:30:33  raceworks172   \n",
       "4   991857623099170816  1296618043745820672 2020-08-21 01:20:06  raceworks172   \n",
       "\n",
       "                                                text               source  \\\n",
       "0  TOYOTA GAZOO Racing photos\\n\\n#TGRgram\\n\\nGT86...                IFTTT   \n",
       "1  New Toyota GR86 Rendered in Different Colors!\\...      Twitter Web App   \n",
       "2  #Toyota86 or #SubaruBRZ ü§∑‚Äç‚ôÇÔ∏è\\nWhich one would ...  Twitter for Android   \n",
       "3  ‚ù§Ô∏è Hand built coilovers on sale with code NOVA...   Twitter for iPhone   \n",
       "4  Daily stance. Because DGAF.\\n\\nhttps://t.co/Qh...   Twitter for iPhone   \n",
       "\n",
       "   display_text_width  is_quote  is_retweet  favorite_count  ...  \\\n",
       "0                 275     False       False              14  ...   \n",
       "1                 119     False       False               2  ...   \n",
       "2                  75     False       False               0  ...   \n",
       "3                 280     False       False               0  ...   \n",
       "4                 238     False       False               3  ...   \n",
       "\n",
       "                       url              profile_url  \\\n",
       "0                      NaN                      NaN   \n",
       "1  https://t.co/JiiC6XyrxF  https://t.co/JiiC6XyrxF   \n",
       "2                      NaN                      NaN   \n",
       "3  https://t.co/N5cLK4Z95U  https://t.co/N5cLK4Z95U   \n",
       "4  https://t.co/N5cLK4Z95U  https://t.co/N5cLK4Z95U   \n",
       "\n",
       "             profile_expanded_url  \\\n",
       "0                             NaN   \n",
       "1           https://www.GR86.org/   \n",
       "2                             NaN   \n",
       "3  https://raceworkscoilovers.com   \n",
       "4  https://raceworkscoilovers.com   \n",
       "\n",
       "                             profile_background_url place_url place_name  \\\n",
       "0                                               NaN       NaN        NaN   \n",
       "1                                               NaN       NaN        NaN   \n",
       "2                                               NaN       NaN        NaN   \n",
       "3  http://abs.twimg.com/images/themes/theme1/bg.png       NaN        NaN   \n",
       "4  http://abs.twimg.com/images/themes/theme1/bg.png       NaN        NaN   \n",
       "\n",
       "  place_full_name place_type country country_code  \n",
       "0             NaN        NaN     NaN          NaN  \n",
       "1             NaN        NaN     NaN          NaN  \n",
       "2             NaN        NaN     NaN          NaN  \n",
       "3             NaN        NaN     NaN          NaN  \n",
       "4             NaN        NaN     NaN          NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Read in 86 JSON data'''\n",
    "toy86 = pd.read_json(\"/Users/avanelson/Desktop/IST652 Python/toy86.JSON\") #read in tweets on Toyota 86\n",
    "\n",
    "len(toy86)\n",
    "toy86.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    0     TOYOTA GAZOO Racing photos\\n\\n#TGRgram\\n...\n",
      "dtype: object\n",
      "Toyota 86 tweets contain 299 tokens\n",
      "n 16\n",
      "tag 13\n",
      "follow 13\n",
      "eatsleepsubaru 13\n",
      "brz 10\n",
      "subaru 5\n",
      "memories 4\n",
      "sti 3\n",
      "frs 3\n",
      "touge 3\n",
      "battle 3\n",
      "ph 3\n",
      "n2015 3\n",
      "nfor 3\n",
      "rules 3\n",
      "fe 2\n",
      "new 2\n",
      "like 2\n",
      "car 2\n",
      "wrx 2\n",
      "toyota 2\n",
      "next 2\n",
      "last 2\n",
      "carbon 2\n",
      "miles 2\n",
      "since 2\n",
      "life 2\n",
      "ye 2\n",
      "cafe 2\n",
      "day 2\n",
      "name 2\n",
      "edwinvgerven 1\n",
      "wrx_jan 1\n",
      "ellie.wrx 1\n",
      "subi 1\n",
      "17sti 1\n",
      "cloudburzt 1\n",
      "subiebry 1\n",
      "f 1\n",
      "frankie 1\n",
      "ljayfarris 1\n",
      "ghozti_chick 1\n",
      "@iggy_wrx 1\n",
      "wrxhigh 1\n",
      "thirsti 1\n",
      "@mvrk_007 1\n",
      "outdoors 1\n",
      "calling 1\n",
      "forster 1\n",
      "overland 1\n",
      "getting 1\n",
      "ready 1\n",
      "testing 1\n",
      "weekend 1\n",
      "ao 1\n",
      "wake 1\n",
      "reality 1\n",
      "nothing 1\n",
      "ever 1\n",
      "goes 1\n",
      "plann 1\n",
      "choose 1\n",
      "choo 1\n",
      "i'll 1\n",
      "show 1\n",
      "feels 1\n",
      "nnow 1\n",
      "i'm 1\n",
      "found 1\n",
      "something 1\n",
      "good 1\n",
      "try 1\n",
      "sports 1\n",
      "always 1\n",
      "dreamed 1\n",
      "b 1\n",
      "camber 1\n",
      "jdm 1\n",
      "wheels 1\n",
      "wide 1\n",
      "gt8 1\n",
      "first 1\n",
      "time 1\n",
      "two 1\n",
      "ot 1\n",
      "another 1\n",
      "angle 1\n",
      "r53 1\n",
      "need 1\n",
      "genuine 1\n",
      "front 1\n",
      "lip 1\n",
      "japan 1\n",
      "fitted 1\n",
      "specialized 1\n",
      "roubaix 1\n",
      "took 1\n",
      "test 1\n",
      "run 1\n",
      "laguna 1\n",
      "seca 1\n",
      "years 1\n",
      "30k 1\n",
      "countless 1\n",
      "dream 1\n",
      "real 1\n",
      "love 1\n",
      "creative 1\n",
      "stuff 1\n",
      "nfrom 1\n",
      "nebi 1\n",
      "suns 1\n",
      "tongues 1\n",
      "@stoooart 1\n",
      "nlook 1\n",
      "ae86 1\n",
      "missing 1\n",
      "mods 1\n",
      "forgot 1\n",
      "post 1\n",
      "simple 1\n",
      "yet 1\n",
      "thank 1\n",
      "everyone 1\n",
      "listened 1\n",
      "appa 1\n",
      "smoking 1\n",
      "hot 1\n",
      "today 1\n",
      "many 1\n",
      "thanks 1\n",
      "zerobreau 1\n",
      "@crazywookiee 1\n",
      "already 1\n",
      "planning 1\n",
      "track 1\n",
      "never 1\n",
      "seem 1\n",
      "able 1\n",
      "sleep 1\n",
      "early 1\n",
      "nig 1\n",
      "brazilian 1\n",
      "world 1\n",
      "cup 1\n",
      "national 1\n",
      "team 1\n",
      "mus 1\n",
      "@subiewoo 1\n",
      "better 1\n"
     ]
    }
   ],
   "source": [
    "'''Convert 86 text to list'''\n",
    "toy86words = toy86[['text']].apply(str)\n",
    "print(toy86words)\n",
    "\n",
    "toy86_list = toy86words.to_numpy().tolist()\n",
    "type(toy86_list)\n",
    "\n",
    "#from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "len(toy86_list)\n",
    "toy86_tokens = [tok.lower() for msg in toy86_list for tok in tt.tokenize(msg)]\n",
    "\n",
    "print(\"Toyota 86 tweets contain\", len(toy86_tokens), \"tokens\")\n",
    "\n",
    "\n",
    "'''Frequency Distribution'''\n",
    "#download stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#filter stopwords from tokens\n",
    "toy86_filter_tokens = [] \n",
    "  \n",
    "for w in toy86_tokens: \n",
    "    if w not in nltk_stopwords: \n",
    "        toy86_filter_tokens.append(w) \n",
    "        \n",
    "\n",
    "#view FD to make sure filter worked...\n",
    "toy86_FD = nltk.FreqDist(toy86_filter_tokens)\n",
    "toy86_FD.most_common(30)\n",
    "\n",
    "#Process token list for FD\n",
    "#import re\n",
    "'''def alpha_filter(w): \n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False'''\n",
    "\n",
    "toy86token_list = [tok for tok in toy86_filter_tokens if not alpha_filter(tok)]\n",
    "toy86token_list[:30]\n",
    "\n",
    "#remove hashtag symbol from tokens\n",
    "toy86token_list = [s.replace('#', '') for s in BRZtoken_list]\n",
    "\n",
    "#display word frequency\n",
    "ftoy86_FD = nltk.FreqDist(toy86token_list)\n",
    "top_words = ftoy86_FD.most_common(150)\n",
    "ftoy86 = {}\n",
    "for word, freq in top_words:\n",
    "    if word not in ftoy86.keys():\n",
    "        ftoy86[word] = freq\n",
    "    print(word, freq)\n",
    "    \n",
    "ftoy86_df = pd.DataFrame.from_dict(ftoy86, orient='index' )\n",
    "ftoy86_df.to_csv('/Users/avanelson/Desktop/IST652 Python/Python Project/frequency_toy86.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Scores for the Toyota 86:\n",
      "0    -1\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     2\n",
      "6    -1\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    3\n",
      "14   -1\n",
      "Name: text, dtype: int64\n",
      "The average sentiment toward the Toyota 86 on twitter is 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "'''TOYOTA 86 SENTIMENT ANALYSIS'''\n",
    "\n",
    "#create positive and negative lists (already done)\n",
    "'''pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())'''\n",
    "\n",
    "#define function to generate sentiment from tweets\n",
    "'''def sentiment(tweet):\n",
    "  senti=0\n",
    "  words = [tok.lower() for tok in tt.tokenize(tweet)]\n",
    "  for word in words:\n",
    "    if word in pos_list:\n",
    "      senti += 1\n",
    "    elif word in neg_list:\n",
    "      senti -= 1\n",
    "  return senti\n",
    "'''\n",
    "#apply sentiment function to original dataframe\n",
    "toy86sent = toy86['text'].apply(sentiment)\n",
    "\n",
    "#display results\n",
    "print(\"Sentiment Scores for the Toyota 86:\")\n",
    "print(toy86sent[:15])\n",
    "avg_toy86_sentiment = sum(toy86sent)/len(toy86sent)\n",
    "print(\"The average sentiment toward the Toyota 86 on twitter is\", avg_toy86_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BEGIN HYUNDAI GENESIS COUPE'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>profile_expanded_url</th>\n",
       "      <th>profile_banner_url</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>profile_background_url</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008512625414582272</td>\n",
       "      <td>1298626510568468480</td>\n",
       "      <td>2020-08-26 14:21:02</td>\n",
       "      <td>53Pandakiller</td>\n",
       "      <td>Sometimes things have to end to make a new beg...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://twitch.tv/pandakiller_53</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/10085126...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1148100786...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008512625414582272</td>\n",
       "      <td>1297666170376589312</td>\n",
       "      <td>2020-08-23 22:44:59</td>\n",
       "      <td>53Pandakiller</td>\n",
       "      <td>Usually the best places are places your not al...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://twitch.tv/pandakiller_53</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/10085126...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1148100786...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008512625414582272</td>\n",
       "      <td>1296580481329311744</td>\n",
       "      <td>2020-08-20 22:50:50</td>\n",
       "      <td>53Pandakiller</td>\n",
       "      <td>Some paths never end! üêºüëÄ\\n\\n#MDD #mendosdailys...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://twitch.tv/pandakiller_53</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/10085126...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1148100786...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1008512625414582272</td>\n",
       "      <td>1296921683425726464</td>\n",
       "      <td>2020-08-21 21:26:39</td>\n",
       "      <td>53Pandakiller</td>\n",
       "      <td>Greetings from your local Gen üêºüëÄ\\n\\n#MDD #mend...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>http://twitch.tv/pandakiller_53</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/10085126...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1148100786...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3816177734</td>\n",
       "      <td>1298384769789628416</td>\n",
       "      <td>2020-08-25 22:20:26</td>\n",
       "      <td>vivid_ito</td>\n",
       "      <td>Some body buy me air suspension. #genesiscoupe...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/38161777...</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1232322028...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id            status_id          created_at  \\\n",
       "0  1008512625414582272  1298626510568468480 2020-08-26 14:21:02   \n",
       "1  1008512625414582272  1297666170376589312 2020-08-23 22:44:59   \n",
       "2  1008512625414582272  1296580481329311744 2020-08-20 22:50:50   \n",
       "3  1008512625414582272  1296921683425726464 2020-08-21 21:26:39   \n",
       "4           3816177734  1298384769789628416 2020-08-25 22:20:26   \n",
       "\n",
       "     screen_name                                               text  \\\n",
       "0  53Pandakiller  Sometimes things have to end to make a new beg...   \n",
       "1  53Pandakiller  Usually the best places are places your not al...   \n",
       "2  53Pandakiller  Some paths never end! üêºüëÄ\\n\\n#MDD #mendosdailys...   \n",
       "3  53Pandakiller  Greetings from your local Gen üêºüëÄ\\n\\n#MDD #mend...   \n",
       "4      vivid_ito  Some body buy me air suspension. #genesiscoupe...   \n",
       "\n",
       "                source  display_text_width  is_quote  is_retweet  \\\n",
       "0            Instagram                 143     False       False   \n",
       "1            Instagram                 152     False       False   \n",
       "2            Instagram                 120     False       False   \n",
       "3            Instagram                 128     False       False   \n",
       "4  Twitter for Android                  64     False       False   \n",
       "\n",
       "   favorite_count  ...             profile_expanded_url  \\\n",
       "0               0  ...  http://twitch.tv/pandakiller_53   \n",
       "1               0  ...  http://twitch.tv/pandakiller_53   \n",
       "2               0  ...  http://twitch.tv/pandakiller_53   \n",
       "3               0  ...  http://twitch.tv/pandakiller_53   \n",
       "4               1  ...                              NaN   \n",
       "\n",
       "                                  profile_banner_url  \\\n",
       "0  https://pbs.twimg.com/profile_banners/10085126...   \n",
       "1  https://pbs.twimg.com/profile_banners/10085126...   \n",
       "2  https://pbs.twimg.com/profile_banners/10085126...   \n",
       "3  https://pbs.twimg.com/profile_banners/10085126...   \n",
       "4  https://pbs.twimg.com/profile_banners/38161777...   \n",
       "\n",
       "                                   profile_image_url  \\\n",
       "0  http://pbs.twimg.com/profile_images/1148100786...   \n",
       "1  http://pbs.twimg.com/profile_images/1148100786...   \n",
       "2  http://pbs.twimg.com/profile_images/1148100786...   \n",
       "3  http://pbs.twimg.com/profile_images/1148100786...   \n",
       "4  http://pbs.twimg.com/profile_images/1232322028...   \n",
       "\n",
       "                             profile_background_url place_url place_name  \\\n",
       "0                                               NaN       NaN        NaN   \n",
       "1                                               NaN       NaN        NaN   \n",
       "2                                               NaN       NaN        NaN   \n",
       "3                                               NaN       NaN        NaN   \n",
       "4  http://abs.twimg.com/images/themes/theme1/bg.png       NaN        NaN   \n",
       "\n",
       "  place_full_name place_type country country_code  \n",
       "0             NaN        NaN     NaN          NaN  \n",
       "1             NaN        NaN     NaN          NaN  \n",
       "2             NaN        NaN     NaN          NaN  \n",
       "3             NaN        NaN     NaN          NaN  \n",
       "4             NaN        NaN     NaN          NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Read in Gen Coupe JSON data'''\n",
    "genCoupe = pd.read_json(\"/Users/avanelson/Desktop/IST652 Python/genCoupe.JSON\") #read in tweets on Genesis Coupe\n",
    "\n",
    "len(genCoupe)\n",
    "genCoupe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    0    Sometimes things have to end to make a ne...\n",
      "dtype: object\n",
      "Genesis Coupe tweets contain 133 tokens\n",
      "n 7\n",
      "end 2\n",
      "places 2\n",
      "mdd 2\n",
      "genesiscoupe 2\n",
      "wrenching 2\n",
      "today 2\n",
      "genny 2\n",
      "sometimes 1\n",
      "things 1\n",
      "make 1\n",
      "new 1\n",
      "beg 1\n",
      "usually 1\n",
      "best 1\n",
      "al 1\n",
      "paths 1\n",
      "never 1\n",
      "mendosdailys 1\n",
      "greetings 1\n",
      "local 1\n",
      "gen 1\n",
      "mend 1\n",
      "body 1\n",
      "buy 1\n",
      "air 1\n",
      "suspension 1\n",
      "took 1\n",
      "cool 1\n",
      "rollers 1\n",
      "friends 1\n",
      "cars 1\n",
      "tod 1\n",
      "h 1\n",
      "hero 1\n",
      "needs 1\n",
      "love 1\n",
      "sorry 1\n",
      "forgive 1\n",
      "well 1\n",
      "sounded 1\n",
      "good 1\n",
      "https 1\n",
      "name 1\n",
      "text 1\n",
      "dtype 1\n",
      "object 1\n"
     ]
    }
   ],
   "source": [
    "'''Convert genCoupe text to list'''\n",
    "genCoupewords = genCoupe[['text']].apply(str)\n",
    "print(genCoupewords)\n",
    "\n",
    "genCoupe_list = genCoupewords.to_numpy().tolist()\n",
    "type(genCoupe_list)\n",
    "\n",
    "#from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "len(genCoupe_list)\n",
    "genCoupe_tokens = [tok.lower() for msg in genCoupe_list for tok in tt.tokenize(msg)]\n",
    "\n",
    "print(\"Genesis Coupe tweets contain\", len(genCoupe_tokens), \"tokens\")\n",
    "\n",
    "\n",
    "'''Frequency Distribution'''\n",
    "#download stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#filter stopwords from tokens\n",
    "genCoupe_filter_tokens = [] \n",
    "  \n",
    "for w in genCoupe_tokens: \n",
    "    if w not in nltk_stopwords: \n",
    "        genCoupe_filter_tokens.append(w) \n",
    "        \n",
    "\n",
    "#view FD to make sure filter worked...\n",
    "genCoupe_FD = nltk.FreqDist(genCoupe_filter_tokens)\n",
    "genCoupe_FD.most_common(30)\n",
    "\n",
    "#Process token list for FD\n",
    "#import re\n",
    "'''def alpha_filter(w): \n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False'''\n",
    "\n",
    "genCoupetoken_list = [tok for tok in genCoupe_filter_tokens if not alpha_filter(tok)]\n",
    "genCoupetoken_list[:30]\n",
    "\n",
    "#remove hashtag symbol from tokens\n",
    "genCoupetoken_list = [s.replace('#', '') for s in genCoupetoken_list]\n",
    "\n",
    "#display word frequency\n",
    "fgenCoupe_FD = nltk.FreqDist(genCoupetoken_list)\n",
    "top_words = fgenCoupe_FD.most_common(150)\n",
    "fGenCoupe = {}\n",
    "for word, freq in top_words:\n",
    "    if word not in fGenCoupe.keys():\n",
    "        fGenCoupe[word] = freq\n",
    "    print(word, freq)\n",
    "    \n",
    "fgenCoupe_df = pd.DataFrame.from_dict(fGenCoupe, orient='index' )\n",
    "fgenCoupe_df.to_csv('/Users/avanelson/Desktop/IST652 Python/Python Project/frequency_genCoupe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Scores for the Hyundai Genesis Coupe:\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    1\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    2\n",
      "Name: text, dtype: int64\n",
      "The average sentiment toward the Genesis Coupe on twitter is 0.4\n"
     ]
    }
   ],
   "source": [
    "'''GENESIS COUPE SENTIMENT ANALYSIS'''\n",
    "\n",
    "#create positive and negative lists (already done)\n",
    "'''pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())'''\n",
    "\n",
    "#define function to generate sentiment from tweets\n",
    "'''def sentiment(tweet):\n",
    "  senti=0\n",
    "  words = [tok.lower() for tok in tt.tokenize(tweet)]\n",
    "  for word in words:\n",
    "    if word in pos_list:\n",
    "      senti += 1\n",
    "    elif word in neg_list:\n",
    "      senti -= 1\n",
    "  return senti\n",
    "'''\n",
    "#apply sentiment function to original dataframe\n",
    "genCoupesent = genCoupe['text'].apply(sentiment)\n",
    "\n",
    "#display results\n",
    "print(\"Sentiment Scores for the Hyundai Genesis Coupe:\")\n",
    "print(genCoupesent[:15])\n",
    "avg_genCoupe_sentiment = sum(genCoupesent)/len(genCoupesent)\n",
    "print(\"The average sentiment toward the Genesis Coupe on twitter is\", avg_genCoupe_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BEGIN FORD MUSTANG'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_retweet_count</th>\n",
       "      <th>quoted_user_id</th>\n",
       "      <th>quoted_screen_name</th>\n",
       "      <th>quoted_name</th>\n",
       "      <th>quoted_followers_count</th>\n",
       "      <th>quoted_friends_count</th>\n",
       "      <th>quoted_statuses_count</th>\n",
       "      <th>quoted_location</th>\n",
       "      <th>quoted_description</th>\n",
       "      <th>quoted_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36935178</td>\n",
       "      <td>1299022619115761664</td>\n",
       "      <td>2020-08-27 16:35:01</td>\n",
       "      <td>steedaautosport</td>\n",
       "      <td>Stanced Right üíØ \\n\\nOwner: @gavinb_svt  \\n\\n19...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>206</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36935178</td>\n",
       "      <td>1296848294635868160</td>\n",
       "      <td>2020-08-21 16:35:02</td>\n",
       "      <td>steedaautosport</td>\n",
       "      <td>American Horsepower On Standby üá∫üá∏ \\n\\nOwner: @...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36935178</td>\n",
       "      <td>1296069415138660352</td>\n",
       "      <td>2020-08-19 13:00:03</td>\n",
       "      <td>steedaautosport</td>\n",
       "      <td>#TeamSteeda, Get Ready For The Week 1 Race in ...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36935178</td>\n",
       "      <td>1298297849701109760</td>\n",
       "      <td>2020-08-25 16:35:03</td>\n",
       "      <td>steedaautosport</td>\n",
       "      <td>Where To? ü§î \\n\\nOwner: @derkgt350r \\n\\n2015-20...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>263</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36935178</td>\n",
       "      <td>1297167144086654976</td>\n",
       "      <td>2020-08-22 13:42:02</td>\n",
       "      <td>steedaautosport</td>\n",
       "      <td>Charging Into #SideShotSaturday üèÅ \\n\\n2015-202...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>258</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id            status_id          created_at      screen_name  \\\n",
       "0  36935178  1299022619115761664 2020-08-27 16:35:01  steedaautosport   \n",
       "1  36935178  1296848294635868160 2020-08-21 16:35:02  steedaautosport   \n",
       "2  36935178  1296069415138660352 2020-08-19 13:00:03  steedaautosport   \n",
       "3  36935178  1298297849701109760 2020-08-25 16:35:03  steedaautosport   \n",
       "4  36935178  1297167144086654976 2020-08-22 13:42:02  steedaautosport   \n",
       "\n",
       "                                                text  source  \\\n",
       "0  Stanced Right üíØ \\n\\nOwner: @gavinb_svt  \\n\\n19...  Buffer   \n",
       "1  American Horsepower On Standby üá∫üá∏ \\n\\nOwner: @...  Buffer   \n",
       "2  #TeamSteeda, Get Ready For The Week 1 Race in ...  Buffer   \n",
       "3  Where To? ü§î \\n\\nOwner: @derkgt350r \\n\\n2015-20...  Buffer   \n",
       "4  Charging Into #SideShotSaturday üèÅ \\n\\n2015-202...  Buffer   \n",
       "\n",
       "   display_text_width  is_quote  is_retweet  favorite_count  ...  \\\n",
       "0                 206     False       False               2  ...   \n",
       "1                 275     False       False               2  ...   \n",
       "2                 275     False       False               3  ...   \n",
       "3                 263     False       False               1  ...   \n",
       "4                 258     False       False               4  ...   \n",
       "\n",
       "   quoted_retweet_count quoted_user_id quoted_screen_name quoted_name  \\\n",
       "0                   NaN            NaN                NaN         NaN   \n",
       "1                   NaN            NaN                NaN         NaN   \n",
       "2                   NaN            NaN                NaN         NaN   \n",
       "3                   NaN            NaN                NaN         NaN   \n",
       "4                   NaN            NaN                NaN         NaN   \n",
       "\n",
       "  quoted_followers_count quoted_friends_count quoted_statuses_count  \\\n",
       "0                    NaN                  NaN                   NaN   \n",
       "1                    NaN                  NaN                   NaN   \n",
       "2                    NaN                  NaN                   NaN   \n",
       "3                    NaN                  NaN                   NaN   \n",
       "4                    NaN                  NaN                   NaN   \n",
       "\n",
       "  quoted_location quoted_description quoted_verified  \n",
       "0             NaN                NaN             NaN  \n",
       "1             NaN                NaN             NaN  \n",
       "2             NaN                NaN             NaN  \n",
       "3             NaN                NaN             NaN  \n",
       "4             NaN                NaN             NaN  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Read in Mustang JSON data'''\n",
    "mustang = pd.read_json(\"/Users/avanelson/Desktop/IST652 Python/mustang.JSON\") #read in tweets on Ford Mustang\n",
    "\n",
    "len(mustang)\n",
    "mustang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    0      Stanced Right üíØ \\n\\nOwner: @gavinb_svt ...\n",
      "dtype: object\n",
      "Ford Mustang tweets contain 143 tokens\n",
      "n 8\n",
      "nowner 3\n",
      "ford 3\n",
      "mustang 3\n",
      "n2015 2\n",
      "stanced 1\n",
      "right 1\n",
      "@gavinb_svt 1\n",
      "n19 1\n",
      "american 1\n",
      "horsepower 1\n",
      "standby 1\n",
      "teamsteeda 1\n",
      "get 1\n",
      "ready 1\n",
      "week 1\n",
      "race 1\n",
      "@derkgt350r 1\n",
      "charging 1\n",
      "sideshotsaturday 1\n",
      "living 1\n",
      "arrangement 1\n",
      "includes 1\n",
      "variety 1\n",
      "dream 1\n",
      "car 1\n",
      "brand 1\n",
      "new 1\n",
      "performance 1\n",
      "blue 1\n",
      "musta 1\n",
      "like 1\n",
      "already 1\n",
      "drove 1\n",
      "fordmu 1\n",
      "fastback 1\n",
      "https://t.co/ 1\n",
      "name 1\n",
      "text 1\n",
      "length 1\n",
      "dtype 1\n",
      "object 1\n"
     ]
    }
   ],
   "source": [
    "'''Convert Mustang text to list'''\n",
    "mustangwords = mustang[['text']].apply(str)\n",
    "print(mustangwords)\n",
    "\n",
    "mustang_list = mustangwords.to_numpy().tolist()\n",
    "type(mustang_list)\n",
    "\n",
    "#from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "len(mustang_list)\n",
    "mustang_tokens = [tok.lower() for msg in mustang_list for tok in tt.tokenize(msg)]\n",
    "\n",
    "print(\"Ford Mustang tweets contain\", len(mustang_tokens), \"tokens\")\n",
    "\n",
    "\n",
    "'''Frequency Distribution'''\n",
    "#download stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#filter stopwords from tokens\n",
    "mustang_filter_tokens = [] \n",
    "  \n",
    "for w in mustang_tokens: \n",
    "    if w not in nltk_stopwords: \n",
    "        mustang_filter_tokens.append(w) \n",
    "        \n",
    "\n",
    "#view FD to make sure filter worked...\n",
    "mustang_FD = nltk.FreqDist(mustang_filter_tokens)\n",
    "mustang_FD.most_common(30)\n",
    "\n",
    "#Process token list for FD\n",
    "#import re\n",
    "'''def alpha_filter(w): \n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False'''\n",
    "\n",
    "mustangtoken_list = [tok for tok in mustang_filter_tokens if not alpha_filter(tok)]\n",
    "mustangtoken_list[:30]\n",
    "\n",
    "#remove hashtag symbol from tokens\n",
    "mustangtoken_list = [s.replace('#', '') for s in mustangtoken_list]\n",
    "\n",
    "#display word frequency\n",
    "fmustang_FD = nltk.FreqDist(mustangtoken_list)\n",
    "top_words = fmustang_FD.most_common(150)\n",
    "fMustang = {}\n",
    "for word, freq in top_words:\n",
    "    if word not in fMustang.keys():\n",
    "        fMustang[word] = freq\n",
    "    print(word, freq)\n",
    "    \n",
    "fMustang_df = pd.DataFrame.from_dict(fMustang, orient='index' )\n",
    "fMustang_df.to_csv('/Users/avanelson/Desktop/IST652 Python/Python Project/frequency_mustang.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Scores for the Ford Mustang Coupe:\n",
      "0     1\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     1\n",
      "8     0\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "Name: text, dtype: int64\n",
      "The average sentiment toward the Ford Mustang on twitter is 0.5461538461538461\n"
     ]
    }
   ],
   "source": [
    "'''MUSTANG SENTIMENT ANALYSIS'''\n",
    "\n",
    "#create positive and negative lists (already done)\n",
    "'''pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())'''\n",
    "\n",
    "#define function to generate sentiment from tweets\n",
    "'''def sentiment(tweet):\n",
    "  senti=0\n",
    "  words = [tok.lower() for tok in tt.tokenize(tweet)]\n",
    "  for word in words:\n",
    "    if word in pos_list:\n",
    "      senti += 1\n",
    "    elif word in neg_list:\n",
    "      senti -= 1\n",
    "  return senti\n",
    "'''\n",
    "#apply sentiment function to original dataframe\n",
    "mustangsent = mustang['text'].apply(sentiment)\n",
    "\n",
    "#display results\n",
    "print(\"Sentiment Scores for the Ford Mustang Coupe:\")\n",
    "print(mustangsent[:15])\n",
    "avg_mustang_sentiment = sum(mustangsent)/len(mustangsent)\n",
    "print(\"The average sentiment toward the Ford Mustang on twitter is\", avg_mustang_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''COMPILE SENTIMENTS'''\n",
    "\n",
    "CarSentDF = {'Vehicle': ['Subaru BRZ', 'Toyota 86', 'Genesis Coupe', 'Ford Mustang', 'BRZ+86'], \n",
    "                  '#Tweets': [len(subBRZ), len(toy86), len(genCoupe), len(mustang), len(subBRZ)+len(toy86)], \n",
    "                  '#Tokens': [len(BRZ_tokens), len(toy86_tokens), len(genCoupe_tokens), len(mustang_tokens), len(BRZ_tokens)+len(toy86_tokens)], \n",
    "                  'Sentiment': [avg_BRZ_sentiment, avg_toy86_sentiment, avg_genCoupe_sentiment, avg_mustang_sentiment, (avg_BRZ_sentiment+avg_toy86_sentiment)/2]}\n",
    "CarSentiment_Final = pd.DataFrame(data=CarSentDF)\n",
    "CarSentiment_Final.to_csv('/Users/avanelson/Desktop/IST652 Python/Python Project/car_Sentiment.csv')\n",
    "\n",
    "Stripped_Car_Sent = CarSentiment_Final[2:5]\n",
    "Stripped_Car_Sent\n",
    "Stripped_Car_Sent.to_csv('/Users/avanelson/Desktop/IST652 Python/Python Project/stripped_car_Sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word, frequency]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
